# 人工智能的数学基础
![目录](images/人工智能的数学基础-目录.png)
补充：符号逻辑，图论
## 第一章 特征向量[^Eigenvector]与矩阵分析
#### 向量基础
[^Eigenvector]: <span style="color:red;">注：此处特征向量不等于线性代数中的特征向量,在机器学习和数据科学中，特征向量通常指一个样本的多维特征表示。</span>  

由单一数值构成的对待研究对象的量化评价，称作<span style="color:blue">标量</span>。标量的定义与其代表的数据类型强相关。
一个用于描述某个对象的​​多维度特征的有序集合​​称为<span style="color:blue">特征向量</span>。用[ ]标注。
由各个特征可能的取值张成的空间，称作“特征空间”。显然，特征空间限制了特征向量的取值范围。
$$\boldsymbol{x}=[x_1,x_2,x_3,...,x_d]$$
给定任一向量，其包含<span style="color:red">大小[^size]与方向</span>两类信息。
[^size]:我们常常使用两点间距离的平方和(**欧氏距离**)表示大小，即$\|\boldsymbol{x}\|=\sqrt{x_1^2+x_2^2+x_3^2+...+x_d^2}$或$\sqrt{\sum_{i=1}^dx_i^2}$但是请注意，大小不要局限于欧氏距离

$\boldsymbol{x_1}=[x_{1,1},x_{1,2},x_{1,3},...,x_{1,d}]\quad \boldsymbol{x_2}=[x_{2,1},x_{2,2},x_{2,3},...,x_{2,d}]$
相应地，只有分别在各分量位置处取相同值时，两个向量才相等（意味两个向量在空间中同一点）。$x_{1,i}=x_{2,i}$
几类特殊的向量：
零向量：$\boldsymbol{o}=[0,0,0,0,...,0]$
单位向量：$\boldsymbol{e}=\frac{\boldsymbol{x}}{\|\boldsymbol{x}\|}$
向量的转置：略
#### 向量运算
**向量加法**：向量加法是指将两个​​同维度​​的向量按照对应分量相加，得到一个新向量的运算。
**向量数乘**：数乘是指用一个标量（实数）乘以向量，每个分量都乘以该标量
**单位元**：在某种运算下，与任何元素结合都保持该元素不变。在线性代数中，向量的单位元是​​零向量​​。
**逆元**：对于向量加法，一个向量$\boldsymbol{u}$的逆元是它的​​**负向量**​​，记作$\boldsymbol{−u}$
**零元**：一个广义术语，泛指具有“归零”或“湮灭”性质的元素。在向量加法中，​​单位元​​是零向量 0,在标量乘法中，​​零向量​​是“零元”，即 0⋅$\boldsymbol{x=0}$,标量 0 是标量域中的零元，但不是向量空间的“零元”。
**向量内积**：对于两个维度相同的向量，它们的内积是其​​对应分量乘积之和​​，结果是一个​​标量​​（长度仅有一个维度向量，转置等于自身）。（满足交换律）
内积结果为0，说明两个向量正交，如果这两个向量均为单位向量，则称这种正交为*标准正交*。
若两个内积向量均已单位化，则向量内积可以作为两个*向量相似程度的判据*,单位向量的内积即为​​余弦相似度。长度确定情况下，内积越接近长度的乘积，则向量在方向上越相似。
用于改写给定函数的泰勒展开式+内积向量方向正好相反时，内积结果取最小值=*梯度降*
内积运算是行向量与列向量的乘积
**分类平面（决策边界）**：​​一个（或一组）用于将特征空间划分成不同类别区域的​​边界​​。与法向量同侧的向量为正，异侧为负。
设有平面方程：$ag+bh+cr+d=0$
扩展特征向量$\boldsymbol{x_c}=[g,h,r,1]\quad$权重向量$\boldsymbol{w}=[a,b,c,d]$
则该平面方程可以改写为向量形式$\boldsymbol{w·x_c^T=0}$
几何意义：$\boldsymbol{w·x_c^T}=0$是$ag+bh+cr+d=0$的等价向量表述形式，它们描述了同一个分类平面。权重向量$\boldsymbol{w}$的前三个分量$[a,b,c]$构成了分类平面的法向量，指出平面方向，即决策得分（$\boldsymbol{w·x^T}$）为正的一侧。
**向量外积**：向量外积是列向量与行向量的矩阵乘积。其运算结果是一个矩阵，该矩阵的每个元素都是列向量的一个分量与行向量的一个分量进行数乘（标量乘法）的结果。
**分量乘法（Hadamard积）**：分量乘法用$\odot$来表示，对于两个维度相同的向量：$\boldsymbol{w}=[w_1,w_2,w_3,...,w_d]\quad\boldsymbol{x}=[x_1,x_2,x_3,...,x_d]$它们的Hadamard积（分量乘法）定义为对应分量相乘，结果是一个新的同维向量：
$\boldsymbol{w\odot x}=[w_1x_1,w_2x_2,w_3x_3,...,w_dx_d]
$
一般地，特征分量对于分类或评分结果的贡献度不一定相同。Hadamard积提供了一种​​为每个特征分量施加不同权重​​的直接方式，从而体现各分量的差异化影响效果。
#### 向量线性相关性
任意向量，总能通过同一向量空间中其余向量得到。限定只包含**数乘与加法运算**————线性运算。
取向量空间中一组向量 $\boldsymbol{x_1,x_2,x_3,...,x_n}$，当且仅当标量值$a_1,a_2,...,a_n$均等于0，$a_1\boldsymbol{x}_1 + a_2\boldsymbol{x}_2 + \cdots + a_n\boldsymbol{x}_n = \boldsymbol{0}$才成立,则称$\boldsymbol{x_1,x_2,x_3,...,x_n}$为**线性无关**的，​​ 反之称这组向量为**线性相关**的，（如二维线性相关的两个向量共线，3维线性相关的两个向量共面）。
线性相关意味着其中至少有一个向量可以表示为其他向量的线性组合（即数乘与加法运算）。也就是说其中任意一个向量**不能**写成由其它向量的数乘与加法运算构成的线性组合时，该向量组为线性无关向量组。
如果对于向量空间中的一个线性无关向量组，不存在空间中另一个向量可以加入该向量组并保持向量组的线性无关，则该向量组为**极大线性无关组**能生成整个向量空间的向量集合，称为该空间的**​​生成组**​​。如果一个生成组中​​不包含任何冗余的向量​​（即去掉其中任何一个向量都无法再生成整个空间），则称它为​**​极小生成组**​​。
互不线性相关的最大集合是构成对应向量空间的向量的最小集合————**基向量**，基向量等价于同时满足极大线性无关组与极小生成组的向量。
